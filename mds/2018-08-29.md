# 2018-08-29

标签（空格分隔）： CASIA

---

## 1.解决报错

```
Traceback (most recent call last):
  File "./src/demo.py", line 17, in <module>
    import tensorflow as tf
  File "/home/lizhonghuan/projects/env/local/lib/python2.7/site-packages/tensorflow/__init__.py", line 24, in <module>
    from tensorflow.python import *
  File "/home/lizhonghuan/projects/env/local/lib/python2.7/site-packages/tensorflow/python/__init__.py", line 72, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File "/home/lizhonghuan/projects/env/local/lib/python2.7/site-packages/tensorflow/python/__init__.py", line 61, in <module>
    from tensorflow.python import pywrap_tensorflow
  File "/home/lizhonghuan/projects/env/local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py", line 28, in <module>
    _pywrap_tensorflow = swig_import_helper()
  File "/home/lizhonghuan/projects/env/local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow', fp, pathname, description)
ImportError: libcudart.so.8.0: cannot open shared object file: No such file or directory


Failed to load the native TensorFlow runtime.

See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/get_started/os_setup.md#import_error

for some common reasons and solutions.  Include the entire stack trace
```
运行提示缺少libcudart.so.8.0，怀疑是因为没有安装cuda8.0，使用以下方法解决，是没有安装tensorflow的gpu版本
```
$ pip install tensorflow-gpu
```

config包下明明有module，不明的原因？
```
ModuleNotFoundError: No module named x
```

## 2. 翻译

### 2. 相关工作

A. 3维激光雷达点元的语义分割
以前的工作在激光雷达分割中看到了广泛的粒度范围，处理从特定组件到整个管道的任何事情。[7]提出了基于网格的地面和基于局部表面凹凸性的目标分割。[2]总结了几种基于迭代算法的诸如RANSAC (random sample consensus)和GP-INSAC (gaussian process incremental sample consensus)的地面去除方法。最近的工作也集中在算法效率上。[5]提出了有效的地面分割和聚类算法，而[13]绕过地面分割直接提取前景对象。[4]将重点扩展到整个管道，包括分割、聚类和分类。提出了将点斑块重新划分为不同类别的背景和前景对象，然后使用EMST-RANSAC[5]进一步集群实例。

B. 3D点云CNN
CNN方法考虑的是二维或三维的激光雷达点云。处理二维数据时考虑的是用激光雷达点云投影自顶向下[14]或从许多其他视图[15]投影的原始图像。其他工作考虑的是三维数据本身，将空间离散为体素和工程特征，如视差、平均和饱和度[16]。无论数据准备如何，深度学习方法都考虑利用二维卷积[17]或三维卷积[18]神经网络的端对端模型。

C. 图像的语义分割
CNNs和CRFs都被用于图像的语义分割任务。[8]提议将经过分类训练的CNN模型转换为完全卷积网络来预测像素级标签。[9]提出了一种用于图像分割的CRF公式，并用均值-场迭代算法近似求解。CNNs和CRFs合并在[10]中，CNN用于生成初始概率图，CRF用于细化和恢复细节。在[11]中，平均场迭代被重新表述为一个递归神经网络(RNN)模块。

D. 模拟数据采集
获取注释，特别是点或像素级的注释对于计算机视觉任务来说通常是非常困难的。因此，合成数据集引起了越来越多的关注。在自动驾驶社区中，视频游戏《侠盗猎车手》被用来检索数据，用于目标检测和分割[19]、[20]。

### 3.方法描述

A. 点云转换

传统CNN模型操作图像,可以由3-dimentional张量的大小 H × W × 3表示。前二维编码空间位置，其中H和W分别为图像高度和宽度。最后一个维度编码特性，最常见的是RGB值。然而，三维激光雷达点云通常表示为一组笛卡尔坐标(x, y, z)，也可以包含额外的特征，如强度或RGB值。与图像像素的分布不同，激光雷达点云的分布通常是稀疏而不规则的。因此，纯粹地将3D空间离散为立体像素会导致过多的空voxels。处理这样的稀疏数据是低效的，浪费计算。
为了获得更紧凑的表示，我们将激光雷达点云投射到一个球体上，以实现密集的、基于网格的表示：

$$ \theta = arcsin\frac{z}{\sqrt{x^2+y^2+z^2}}, \widetilde{\theta} = \lfloor \theta / \Delta\theta \rfloor ,$$

$$ \phi = arcsin\frac{z}{\sqrt{x^2+y^2}}, \widetilde{\phi} = \lfloor \phi / \Delta\phi \rfloor \tag{1}$$

$\phi$ 和 $\theta$分别为方位角和顶角，如图2中A所示。

![Fig2-A][1]

$\Delta\theta$ 和 $\Delta\phi$ 是离散化的分辨率，( $\widetilde{\theta}$ ,  $\widetilde{\phi}$ )表示2D球面网格上的点的位置。将等式（1）应用于云中的每个点，我们可以获得大小为H × W × C的3D张量。在本文中，我们考虑从具有64个垂直通道的Velodyne HDL-64E LiDAR收集的数据，因此H = 64。受KITTI数据集的数据注释的限制，我们只考虑90°的前视图区域并将其划分为512个网格所以W = 512。C是每个点的特征数。在我们的实验中，我们为每个点使用了5个特征：3个笛卡尔坐标（x，y，z），强度测量和范围 $r=\sqrt{x^2+y^2+z^2}$。投影点云的示例可以在图2（B）中找到。可以看出，这种表示是密集且规则地分布的，类似于普通图像（图2（C））。

![Fig2-B-C][2]

这种特征使我们能够避免手工制作的功能，从而提高我们的表现形式所概括的几率。

B. 网络结构

我们的卷积神经网络结构如图3所示。

![Fig 3][3]

SqueezeSeg源自SqueezeNet[12]，这是一种轻量级CNN，可以实现AlexNet[21]级精度，参数减少50倍。
SqueezeSeg的输入是64 × 512 × 5张量，如上一节所述。我们从SqueezeNet移植层（conv1a到fire9）以进行特征提取。SqueezeNet使用max-pooling来对宽度和高度尺寸的中间特征图进行下采样，但由于我们的输入张量高度远小于宽度，我们只对宽度进行下采样。fire9的输出是一个下采样的特征映射，它对点云的语义进行编码。
为了获得每个点的全分辨率标签预测，我们使用反卷积模块（更确切地说，“转置卷积”）来对宽度维度中的特征映射进行上采样。 我们使用跳过连接将上采样特征映射添加到相同大小的低级特征映射，如图3所示。输出概率图由具有softmax激活的卷积层（conv14）生成。概率图由循环CRF层进一步细化，这将在下一节中讨论。
为了减少模型参数和计算的数量，我们用fireModules [12]和fireDeconvs替换了卷积和反卷积层。两个模块的体系结构如图4所示。

![Fig 4][4]

在fireModule中，大小为H×W×C的输入张量首先被馈入1x1卷积，以将信道大小减小到C/4。接下来，使用3x3卷积来融合空间信息。与并行1x1卷积一起，它们恢复C的通道大小。输入1x1卷积称为挤压层，并行1x1和3x3卷积合称为扩展层。给定匹配的输入和输出大小，3x3卷积层需要 $9C^2$ 参数以及 $9HWC^2$ 的运算量，而fireModule只需要 $\frac32C^2$ 参数和 $\frac32HWC^2$ 的计算。在fireDeconv模块中，用于对特征贴图进行上采样的解卷积图层位于挤压和扩展图层之间。~~要将宽度尺寸上采样2~~，常规的1x4反卷积层必须包含 $4C^2$ 参数和 $4HWC^2$ 计算。然而，使用fireDeconv，我们只需要 $\frac74C^2$ 参数和 $\frac74C^2$ 计算。

C. 条件随机场

通过图像分割，CNN模型预测的标签图往往具有模糊的边界。 这是由于在下采样操作（例如最大池）中丢失了低级细节。 SqueezeSeg中也观察到类似的现象。
准确的逐点标签预测不仅需要了解对象和场景的高级语义，还需要了解低级细节。 后者对于标签分配的一致性至关重要。 例如，如果云中的两个点彼此相邻并且具有相似的强度测量值，则它们可能属于同一对象并因此具有相同的标签。 在[10]之后，我们使用条件随机场（CRF）来细化由CNN生成的标签图。 对于给定的点云和标签预测c，其中$c_i$表示第i个点的预测标签，CRF模型使用能量函数：

$$ E(c) = \sum_iu_i(c_i) + \sum_{i,j}b_{i,j}(c_i,c_j) \tag2$$

一元多项式 $ u_i(c_i) = -logP(c_i)$ 考虑来自CNN分类器的预测概率 $ P(c_i)$。二元多项式定义了用于将不同标签分配给一对相似点的“惩罚”，并且被定义为 

$$ b_{i,j}(c_i,c_j) = \mu(c_i,c_j)\sum^M_{m=1}\omega_mk^m(ƒ_i,ƒ_j) $$

其中 $ \mu(c_i,c_j) = 1 , c_i \neq c_j 且 c_i,c_j \neq 0 $，$ k^m $是第m个高斯核，其取决于点i和j的特征ƒ，并且 $ \omega_m$ 是相应的系数。

在我们的工作中，我们使用了两个高斯核：

$$ \omega_1exp(-\frac{\mid\mid\mathcal{P_i}-\mathcal{P_j\mid\mid^2}
}{2\sigma_\alpha^2}-\frac{\mid\mid\mathcal{X_i}-\mathcal{X_j}\mid\mid^2}{2\sigma_\beta^2}) $$ $$ +\omega_2exp(-\frac{{\mid\mid}\mathcal{P_i}-\mathcal{P_j}{\mid\mid}^2
}{2\sigma_\gamma^2}). \tag3 $$

第一项取决于两个点的角位置 $ \mathcal{P}(\widetilde{\theta},\widetilde{\phi}) $ 和笛卡尔坐标 $ X(x,y,z)$。第二项仅取决于角度位置。  $ \sigma_\alpha $ ，$ \sigma_\beta $ 和 $ \sigma_\gamma $ 是根据经验选择的三个超参数。还可以包括强度和RGB值等额外功能。

DeepGTAV[^1]

## 3. Numpy

### 广播Broadcasting
> 广播是一种强有力的机制，它让Numpy可以让不同大小的矩阵在一起进行数学计算。我们常常会有一个小的矩阵和一个大的矩阵，然后我们会需要用小的矩阵对大的矩阵做一些计算。

```
import numpy as np

# We will add the vector v to each row of the matrix x,
# storing the result in the matrix y
x = np.array([[1,2,3], [4,5,6], [7,8,9], [10, 11, 12]])
v = np.array([1, 0, 1])
y = np.empty_like(x)   # Create an empty matrix with the same shape as x

# Add the vector v to each row of the matrix x with an explicit loop
for i in range(4):
    y[i, :] = x[i, :] + v

# Now y is the following
# [[ 2  2  4]
#  [ 5  5  7]
#  [ 8  8 10]
#  [11 11 13]]
print y
```
这样是行得通的，但是当x矩阵非常大，利用循环来计算就会变得很慢很慢。我们可以换一种思路：
```
import numpy as np

# We will add the vector v to each row of the matrix x,
# storing the result in the matrix y
x = np.array([[1,2,3], [4,5,6], [7,8,9], [10, 11, 12]])
v = np.array([1, 0, 1])
vv = np.tile(v, (4, 1))  # Stack 4 copies of v on top of each other
print vv                 # Prints "[[1 0 1]
                         #          [1 0 1]
                         #          [1 0 1]
                         #          [1 0 1]]"
y = x + vv  # Add x and vv elementwise
print y  # Prints "[[ 2  2  4
         #          [ 5  5  7]
         #          [ 8  8 10]
         #          [11 11 13]]"
```
Numpy广播机制可以让我们不用创建vv，就能直接运算：
```
import numpy as np

# We will add the vector v to each row of the matrix x,
# storing the result in the matrix y
x = np.array([[1,2,3], [4,5,6], [7,8,9], [10, 11, 12]])
v = np.array([1, 0, 1])
y = x + v  # Add v to each row of x using broadcasting
print y  # Prints "[[ 2  2  4]
         #          [ 5  5  7]
         #          [ 8  8 10]
         #          [11 11 13]]"
```
对两个数组的广播机制要遵守规则：
[规则文档](https://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)


[^1]:[https://github.com/ai-tor/DeepGTAV](https://github.com/ai-tor/DeepGTAV)


  [1]: http://static.zybuluo.com/usiege/2xgd1iorpcf0gzbpawpj9y2b/image_1cm2c1jdichq1gie9e31g9vjbl9.png
  [2]: http://static.zybuluo.com/usiege/diwywed90f96nzo0ulu2a1nm/image_1cm2ehb61et17gjbki1to11eta16.png
  [3]: http://static.zybuluo.com/usiege/y1b2hheqi3kx18x3f5n4g92y/image_1cm2f0qar1p6qrj71m9n1h3f1vbj23.png
  [4]: http://static.zybuluo.com/usiege/bzilgu4v6286a0yhvota6loq/image_1cm2p3mmhc5m1n7r1qddecf5ds2g.png